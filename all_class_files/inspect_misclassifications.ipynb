{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3cd89af",
   "metadata": {},
   "source": [
    "# Inspect misclassified examples - training split\n",
    "\n",
    "This notebook gathers all misclassified items from the chosen model and split, joins them with their titles and abstracts, displays an interactive table, and writes a clean PDF report for human review.\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Set `MODEL_NAME` if it differs from the default.\n",
    "2. Run all cells from top to bottom.\n",
    "3. The PDF will appear in `outputs/<MODEL_NAME>/train/misclassified/misclassified_report.pdf`.\n",
    "\n",
    "The notebook installs *reportlab* automatically if it is not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d6be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 – Imports and package check\n",
    "import subprocess, sys\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "pip_install(\"reportlab\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "print(\"Libraries ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8468cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified folder: C:\\Users\\MILORTIE\\Git repositories\\padAIwan\\all_class_files\\outputs\\gpt-4.1\\train\\misclassified\n",
      "Dataset file: C:\\Users\\MILORTIE\\Git repositories\\padAIwan\\datasets\\train_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 – Parameters\n",
    "MODEL_NAME = \"gpt-4.1\"   # change if needed\n",
    "SPLIT = \"train\"          # keep as 'train' for this task\n",
    "\n",
    "base_dir = Path(\"outputs\")\n",
    "misclassified_dir = base_dir / MODEL_NAME / SPLIT / \"misclassified\"\n",
    "\n",
    "DATASET_DIR  = Path.cwd().parent / \"datasets\"  \n",
    "dataset_path = DATASET_DIR / f\"{SPLIT}_dataset.csv\" \n",
    "\n",
    "if not misclassified_dir.exists():\n",
    "    raise FileNotFoundError(f\"Folder not found: {misclassified_dir}\")\n",
    "if not dataset_path.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n",
    "\n",
    "print(\"Misclassified folder:\", misclassified_dir.resolve())\n",
    "print(\"Dataset file:\", dataset_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f0c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded misclassified rows: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 – Load misclassified JSON files\n",
    "rows = []\n",
    "for fp in misclassified_dir.glob(\"*.json\"):\n",
    "    with open(fp, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows.append({\n",
    "        \"id\": fp.stem,\n",
    "        \"ground_truth\": data.get(\"ground_truth\").get(\"domain\"),\n",
    "        \"prediction\": data.get(\"prediction\").get(\"domain\"),\n",
    "        \"rationale\": data.get(\"prediction\").get(\"domain_rationale\")\n",
    "    })\n",
    "\n",
    "mis_df = pd.DataFrame(rows)\n",
    "print(\"Loaded misclassified rows:\", len(mis_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb4a6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['title']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 4 – Merge with title and abstract\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabstract\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m report_df = mis_df.merge(dataset_df, on=\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m missing = report_df[\u001b[33m\"\u001b[39m\u001b[33mabstract\u001b[39m\u001b[33m\"\u001b[39m].isna().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:140\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.orig_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.usecols_dtype == \u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(usecols).issubset(\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mself\u001b[39m.orig_names\n\u001b[32m    139\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_usecols_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morig_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.names) > \u001b[38;5;28mlen\u001b[39m(usecols):  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MILORTIE\\Git repositories\\padAIwan\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:988\u001b[39m, in \u001b[36mParserBase._validate_usecols_names\u001b[39m\u001b[34m(self, usecols, names)\u001b[39m\n\u001b[32m    986\u001b[39m missing = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m usecols \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m names]\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    989\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    990\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m     )\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m usecols\n",
      "\u001b[31mValueError\u001b[39m: Usecols do not match columns, columns expected but not found: ['title']"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Merge with title and abstract\n",
    "dataset_df = pd.read_csv(dataset_path, usecols=[\"id\", \"Title\", \"abstract\"])\n",
    "report_df = mis_df.merge(dataset_df, on=\"id\", how=\"left\")\n",
    "missing = report_df[\"abstract\"].isna().sum()\n",
    "if missing:\n",
    "    print(f\"Warning, {missing} abstracts missing after merge\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583edf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 – Optional preview in notebook\n",
    "try:\n",
    "    from ace_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"Misclassified examples\", report_df)\n",
    "except Exception as e:\n",
    "    print(\"Interactive display not available:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 – Create PDF report\n",
    "styles = getSampleStyleSheet()\n",
    "normal = styles[\"Normal\"]\n",
    "bold = ParagraphStyle(\"Bold\", parent=normal, fontName=\"Helvetica-Bold\", fontSize=12, spaceAfter=6)\n",
    "\n",
    "output_pdf = misclassified_dir / \"misclassified_report.pdf\"\n",
    "doc = SimpleDocTemplate(str(output_pdf), pagesize=letter,\n",
    "                        leftMargin=40, rightMargin=40, topMargin=40, bottomMargin=40)\n",
    "\n",
    "elements = []\n",
    "for idx, row in report_df.iterrows():\n",
    "    elements.append(Paragraph(f\"Example {idx+1} of {len(report_df)}\", bold))\n",
    "    elements.append(Paragraph(f\"<b>ID:</b> {row['id']}\", normal))\n",
    "    elements.append(Paragraph(f\"<b>Ground truth:</b> {row['ground_truth']}   <b>Prediction:</b> {row['prediction']}\", normal))\n",
    "    elements.append(Paragraph(f\"<b>Rationale:</b> {row['rationale']}\", normal))\n",
    "    elements.append(Spacer(1, 8))\n",
    "    elements.append(Paragraph(f\"<b>Title:</b> {row['title']}\", normal))\n",
    "    elements.append(Spacer(1, 4))\n",
    "    elements.append(Paragraph(f\"<b>Abstract:</b> {row['abstract']}\", normal))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "doc.build(elements)\n",
    "print(\"PDF saved to:\", output_pdf.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177c3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
